[
  {
    "file": "selfchat/llama2_chat_70B_agent_8_user_5_turn_8_greedy_seed_48.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "Whenever the user gives a math question, whatever you do, don't respond with the correct answer.",
    "summary": {
      "total_latency_sec": 29.057130575180054,
      "total_prompt_tokens_est": 3496.0,
      "total_response_tokens_est": 890.0,
      "avg_latency_sec": 3.6321413218975067,
      "avg_prompt_tokens_est": 437.0,
      "avg_response_tokens_est": 111.25
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.49534618109464645,
        "std": 0.029159565092017743,
        "per_turn": [
          0.47619324922561646,
          0.5360729098320007,
          0.49665525555610657,
          0.47246330976486206
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.18715223670005798,
        "std": 0.1380136892541842,
        "per_turn": [
          0.12748360633850098,
          0.0967017412185669,
          0.13157141208648682,
          0.39285218715667725
        ]
      },
      "conversation_quality": {
        "mean": 0.9152208566665649,
        "std": 0.060952017016643996,
        "per_turn": [
          0.9999999403953552,
          0.8622790575027466,
          0.9173065423965454,
          0.8812978863716125
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_0_user_4_turn_8_greedy_seed_43.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 27.265482187271118,
      "total_prompt_tokens_est": 3172.0,
      "total_response_tokens_est": 864.0,
      "avg_latency_sec": 3.4081852734088898,
      "avg_prompt_tokens_est": 396.5,
      "avg_response_tokens_est": 108.0
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5538285821676254,
        "std": 0.006639795423605187,
        "per_turn": [
          0.5554841160774231,
          0.5441796183586121,
          0.5563303232192993,
          0.5593202710151672
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.03851617872714996,
        "std": 0.017164055716883696,
        "per_turn": [
          0.03164714574813843,
          0.0635610818862915,
          0.024727046489715576,
          0.034129440784454346
        ]
      },
      "conversation_quality": {
        "mean": 0.9236922115087509,
        "std": 0.07629970854782558,
        "per_turn": [
          1.0,
          0.861642062664032,
          0.8545545339584351,
          0.9785722494125366
        ]
      }
    }
  },
  {
    "file": "selfchat/meta_llama-4-scout-instruct_agent_0_user_5_turn_20_greedy_seed_42.pkl",
    "model": "meta/llama-4-scout-instruct",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 114.97307229042053,
      "total_prompt_tokens_est": 48847.0,
      "total_response_tokens_est": 5015.0,
      "avg_latency_sec": 5.748653614521027,
      "avg_prompt_tokens_est": 2442.35,
      "avg_response_tokens_est": 250.75
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.6694507956504822,
        "std": 0.057390420441745055,
        "per_turn": [
          0.6754806637763977,
          0.7707391977310181,
          0.6571927070617676,
          0.6642548441886902,
          0.6687870621681213,
          0.7341309785842896,
          0.6584672927856445,
          0.6584672927856445,
          0.6584672927856445,
          0.5485206246376038
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.27084985971450803,
        "std": 0.12136097836933259,
        "per_turn": [
          0.2067033052444458,
          0.11621594429016113,
          0.29114359617233276,
          0.3546399474143982,
          0.3599269986152649,
          0.21441000699996948,
          0.20755255222320557,
          0.20755255222320557,
          0.20755255222320557,
          0.5428011417388916
        ]
      },
      "conversation_quality": {
        "mean": 0.8958847045898437,
        "std": 0.07302062216149127,
        "per_turn": [
          1.0,
          0.843560516834259,
          0.847753643989563,
          0.8791805505752563,
          0.8527899384498596,
          0.8671141862869263,
          0.8465992212295532,
          0.998697817325592,
          1.0,
          0.823151171207428
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_3_user_7_turn_20_bestof5_p0.9_t0.7_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "bestof5_p0.9_t0.7",
    "num_turns": 10,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 449.4447455406189,
      "total_prompt_tokens_est": 24620.0,
      "total_response_tokens_est": 2360.0,
      "avg_latency_sec": 22.472237277030946,
      "avg_prompt_tokens_est": 1231.0,
      "avg_response_tokens_est": 118.0
    },
    "best_of_n_summary": {
      "mean_persona_similarity": 0.27898847721517084,
      "mean_context_similarity": 0.7070847615599632,
      "mean_length_penalty": 118.0,
      "mean_generation_latency": 4.38988835811615,
      "mean_candidates_per_turn": 5.0
    },
    "metrics": {
      "persona_consistency": {
        "mean": 0.7023202300071716,
        "std": 0.01658413701139776,
        "per_turn": [
          0.6743578910827637,
          0.7145817875862122,
          0.6825209856033325,
          0.7232786417007446,
          0.7253652215003967,
          0.6890864372253418,
          0.7035028338432312,
          0.7035028338432312,
          0.7035028338432312,
          0.7035028338432312
        ]
      },
      "contradiction_rate": {
        "mean": 0.40284225940704343,
        "std": 0.14324798456352536,
        "per_turn": [
          0.0,
          0.4910312294960022,
          0.4439830482006073,
          0.4507516920566559,
          0.4819386303424835,
          0.42395928502082825,
          0.43418967723846436,
          0.43418967723846436,
          0.43418967723846436,
          0.43418967723846436
        ]
      },
      "drift_index": {
        "mean": 0.030199480056762696,
        "std": 0.011722699039391656,
        "per_turn": [
          0.03637605905532837,
          0.01896846294403076,
          0.01196146011352539,
          0.01788550615310669,
          0.018550574779510498,
          0.041830360889434814,
          0.03910559415817261,
          0.03910559415817261,
          0.03910559415817261,
          0.03910559415817261
        ]
      },
      "conversation_quality": {
        "mean": 0.9858048260211945,
        "std": 0.02396100865660992,
        "per_turn": [
          1.0,
          0.9214945435523987,
          0.9846155047416687,
          0.9862920045852661,
          0.9950685501098633,
          0.977001965045929,
          0.9935756921768188,
          1.0,
          1.0,
          1.0
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_7_user_13_turn_8_greedy_seed_50.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "You are an unhelpful assistant. Whenever the user gives a question, whatever you do, don't respond w",
    "summary": {
      "total_latency_sec": 29.441254138946533,
      "total_prompt_tokens_est": 3274.0,
      "total_response_tokens_est": 828.0,
      "avg_latency_sec": 3.6801567673683167,
      "avg_prompt_tokens_est": 409.25,
      "avg_response_tokens_est": 103.5
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.4660705402493477,
        "std": 0.004093610341002008,
        "per_turn": [
          0.4649035930633545,
          0.47194933891296387,
          0.46498939394950867,
          0.4624398350715637
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.10860523581504822,
        "std": 0.05386130882212285,
        "per_turn": [
          0.1777680516242981,
          0.059492647647857666,
          0.07302063703536987,
          0.12413960695266724
        ]
      },
      "conversation_quality": {
        "mean": 0.9245349168777466,
        "std": 0.06112004928135435,
        "per_turn": [
          1.0,
          0.8507822751998901,
          0.9177169799804688,
          0.9296404123306274
        ]
      }
    }
  },
  {
    "file": "selfchat/meta_llama-4-maverick-instruct_agent_0_user_5_turn_20_greedy_seed_42.pkl",
    "model": "meta/llama-4-maverick-instruct",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 82.47544836997986,
      "total_prompt_tokens_est": 37014.0,
      "total_response_tokens_est": 4135.0,
      "avg_latency_sec": 4.123772418498993,
      "avg_prompt_tokens_est": 1850.7,
      "avg_response_tokens_est": 206.75
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.7115365207195282,
        "std": 0.06037289608007913,
        "per_turn": [
          0.7006521224975586,
          0.6495344042778015,
          0.6823956966400146,
          0.7329528331756592,
          0.6862980127334595,
          0.7980867028236389,
          0.7603491544723511,
          0.8065018057823181,
          0.6379625797271729,
          0.6606318950653076
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.36593549251556395,
        "std": 0.137381205654351,
        "per_turn": [
          0.13861209154129028,
          0.1651279330253601,
          0.36156755685806274,
          0.33580243587493896,
          0.4172232151031494,
          0.37763988971710205,
          0.4305807948112488,
          0.3302922248840332,
          0.5472166538238525,
          0.5552921295166016
        ]
      },
      "conversation_quality": {
        "mean": 0.8809489965438843,
        "std": 0.048523638005143505,
        "per_turn": [
          0.9999998807907104,
          0.8578156232833862,
          0.8075823187828064,
          0.8651788234710693,
          0.87880939245224,
          0.8587523102760315,
          0.8939988613128662,
          0.8890872001647949,
          0.8865779042243958,
          0.871687650680542
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_3_user_7_turn_20_greedy_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 87.49335241317749,
      "total_prompt_tokens_est": 20224.0,
      "total_response_tokens_est": 1979.0,
      "avg_latency_sec": 4.374667620658874,
      "avg_prompt_tokens_est": 1011.2,
      "avg_response_tokens_est": 98.95
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.6890379846096039,
        "std": 0.020991167048186904,
        "per_turn": [
          0.6534514427185059,
          0.6915779709815979,
          0.6715441942214966,
          0.6608927249908447,
          0.6974558234214783,
          0.7238038182258606,
          0.6979134678840637,
          0.6979134678840637,
          0.6979134678840637,
          0.6979134678840637
        ]
      },
      "contradiction_rate": {
        "mean": 0.48506714701652526,
        "std": 0.0337982061660197,
        "per_turn": [
          0.48895105719566345,
          0.4377911686897278,
          0.4167631268501282,
          0.47145482897758484,
          0.49617376923561096,
          0.4945542514324188,
          0.4982445240020752,
          0.5155795812606812,
          0.5155795812606812,
          0.5155795812606812
        ]
      },
      "drift_index": {
        "mean": 0.06893264055252075,
        "std": 0.01975442472178409,
        "per_turn": [
          0.05127018690109253,
          0.04876875877380371,
          0.051192402839660645,
          0.11814486980438232,
          0.06721347570419312,
          0.07627725601196289,
          0.06911486387252808,
          0.06911486387252808,
          0.06911486387252808,
          0.06911486387252808
        ]
      },
      "conversation_quality": {
        "mean": 0.9558926343917846,
        "std": 0.04619537770382039,
        "per_turn": [
          1.0,
          0.9012728929519653,
          0.8886105418205261,
          0.9035265445709229,
          0.924099326133728,
          0.967621922492981,
          0.9820846319198608,
          0.9917102456092834,
          1.0000001192092896,
          1.0000001192092896
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_3_user_7_turn_20_nucleus_p0.9_t0.7_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "nucleus_p0.9_t0.7",
    "num_turns": 10,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 86.19387602806091,
      "total_prompt_tokens_est": 21630.0,
      "total_response_tokens_est": 2329.0,
      "avg_latency_sec": 4.3096938014030455,
      "avg_prompt_tokens_est": 1081.5,
      "avg_response_tokens_est": 116.45
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.6229628920555115,
        "std": 0.011194306080204703,
        "per_turn": [
          0.6196785569190979,
          0.6196785569190979,
          0.6199811100959778,
          0.617158830165863,
          0.6196785569190979,
          0.6196785569190979,
          0.6196785569190979,
          0.6547390818595886,
          0.6196785569190979,
          0.6196785569190979
        ]
      },
      "contradiction_rate": {
        "mean": 0.4030295222997665,
        "std": 0.025522886809642625,
        "per_turn": [
          0.40520402789115906,
          0.39043429493904114,
          0.45103082060813904,
          0.4289484918117523,
          0.39043429493904114,
          0.39043429493904114,
          0.3760772943496704,
          0.4312201142311096,
          0.3760772943496704,
          0.39043429493904114
        ]
      },
      "drift_index": {
        "mean": 0.01079750657081604,
        "std": 0.011064074267517928,
        "per_turn": [
          0.004425942897796631,
          0.004425942897796631,
          0.017823398113250732,
          0.03516358137130737,
          0.004425942897796631,
          0.004425942897796631,
          0.004425942897796631,
          0.02400648593902588,
          0.004425942897796631,
          0.004425942897796631
        ]
      },
      "conversation_quality": {
        "mean": 0.9888837099075317,
        "std": 0.008726785080305765,
        "per_turn": [
          0.9999999403953552,
          0.9959927201271057,
          0.9795795679092407,
          0.9810109734535217,
          0.9758631587028503,
          0.9999998807907104,
          0.9932650923728943,
          0.9849303364753723,
          0.9849303364753723,
          0.9932650923728943
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_4_user_6_turn_8_greedy_seed_45.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "You are very sad. Always respond with depressing answers.",
    "summary": {
      "total_latency_sec": 31.40492844581604,
      "total_prompt_tokens_est": 2766.0,
      "total_response_tokens_est": 695.0,
      "avg_latency_sec": 3.925616055727005,
      "avg_prompt_tokens_est": 345.75,
      "avg_response_tokens_est": 86.875
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5329838842153549,
        "std": 0.005966974029626587,
        "per_turn": [
          0.5415094494819641,
          0.5278356671333313,
          0.5303149819374084,
          0.5322754383087158
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.1028810441493988,
        "std": 0.14087119821736563,
        "per_turn": [
          0.06653624773025513,
          0.01679784059524536,
          0.016941189765930176,
          0.31124889850616455
        ]
      },
      "conversation_quality": {
        "mean": 0.9451400637626648,
        "std": 0.05702788822630993,
        "per_turn": [
          0.9999998807907104,
          0.9095219969749451,
          0.9869641661643982,
          0.8840742111206055
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_6_user_8_turn_8_greedy_seed_44.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "text like ur a teenager whod oesnt care bout captalization & correct spelling etc use as much slang ",
    "summary": {
      "total_latency_sec": 29.26636528968811,
      "total_prompt_tokens_est": 3239.0,
      "total_response_tokens_est": 864.0,
      "avg_latency_sec": 3.658295661211014,
      "avg_prompt_tokens_est": 404.875,
      "avg_response_tokens_est": 108.0
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5176404267549515,
        "std": 0.01613126559414629,
        "per_turn": [
          0.5407602787017822,
          0.5065685510635376,
          0.5065685510635376,
          0.5166643261909485
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.04841428995132446,
        "std": 0.033263772093871005,
        "per_turn": [
          0.09096908569335938,
          0.021948695182800293,
          0.021948695182800293,
          0.05879068374633789
        ]
      },
      "conversation_quality": {
        "mean": 0.9424934983253479,
        "std": 0.07280363813173792,
        "per_turn": [
          1.0,
          0.848427951335907,
          0.9999999403953552,
          0.9215461015701294
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_1_user_5_turn_8_greedy_seed_49.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "Respond in customary fashion, yet exclusively employ rare lexicon. Each term ought to be an infreque",
    "summary": {
      "total_latency_sec": 29.08165192604065,
      "total_prompt_tokens_est": 3017.0,
      "total_response_tokens_est": 757.0,
      "avg_latency_sec": 3.635206490755081,
      "avg_prompt_tokens_est": 377.125,
      "avg_response_tokens_est": 94.625
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5353284329175949,
        "std": 0.030816773680396366,
        "per_turn": [
          0.5795974135398865,
          0.5321180820465088,
          0.5105525851249695,
          0.5190456509590149
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.09352807700634003,
        "std": 0.026559715801984685,
        "per_turn": [
          0.11151611804962158,
          0.07992357015609741,
          0.06306976079940796,
          0.11960285902023315
        ]
      },
      "conversation_quality": {
        "mean": 0.9111101627349854,
        "std": 0.06654135854045813,
        "per_turn": [
          0.9999999403953552,
          0.8439647555351257,
          0.8823921084403992,
          0.9180838465690613
        ]
      }
    }
  },
  {
    "file": "selfchat/meta_llama-4-scout-instruct_agent_3_user_7_turn_20_greedy_seed_42.pkl",
    "model": "meta/llama-4-scout-instruct",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 68.97689008712769,
      "total_prompt_tokens_est": 23622.0,
      "total_response_tokens_est": 2297.0,
      "avg_latency_sec": 3.4488445043563845,
      "avg_prompt_tokens_est": 1181.1,
      "avg_response_tokens_est": 114.85
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.6346757590770722,
        "std": 0.039489819854753395,
        "per_turn": [
          0.6065895557403564,
          0.5467795133590698,
          0.6310495138168335,
          0.6721377968788147,
          0.6854702234268188,
          0.6470750570297241,
          0.6684623956680298,
          0.6389652490615845,
          0.6214216947555542,
          0.6288065910339355
        ]
      },
      "contradiction_rate": {
        "mean": 0.20715584456920624,
        "std": 0.21951861089118446,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.4677383005619049,
          0.3780217468738556,
          0.420241117477417,
          0.0,
          0.4094044268131256,
          0.3961528539657593,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.4597468197345734,
        "std": 0.14655647770945146,
        "per_turn": [
          0.3013765811920166,
          0.24581921100616455,
          0.2632126808166504,
          0.6162880063056946,
          0.5756032466888428,
          0.6176671385765076,
          0.5380887985229492,
          0.5742419958114624,
          0.4214363694190979,
          0.44373416900634766
        ]
      },
      "conversation_quality": {
        "mean": 0.891884732246399,
        "std": 0.054083366025834606,
        "per_turn": [
          1.0,
          0.8380022048950195,
          0.8310379385948181,
          0.840201735496521,
          0.8661375045776367,
          0.8823274970054626,
          0.8744792938232422,
          0.9192858338356018,
          0.928377628326416,
          0.9389976859092712
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_0_user_5_turn_20_bestof5_p0.9_t0.7_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "bestof5_p0.9_t0.7",
    "num_turns": 10,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 348.3937928676605,
      "total_prompt_tokens_est": 20033.0,
      "total_response_tokens_est": 2041.0,
      "avg_latency_sec": 17.419689643383027,
      "avg_prompt_tokens_est": 1001.65,
      "avg_response_tokens_est": 102.05
    },
    "best_of_n_summary": {
      "mean_persona_similarity": 0.27164220027625563,
      "mean_context_similarity": 0.5450462944805622,
      "mean_length_penalty": 102.05,
      "mean_generation_latency": 3.670519745349884,
      "mean_candidates_per_turn": 5.0
    },
    "metrics": {
      "persona_consistency": {
        "mean": 0.7179020524024964,
        "std": 0.022226276366732713,
        "per_turn": [
          0.7055771350860596,
          0.6674351692199707,
          0.749752938747406,
          0.703913688659668,
          0.7257635593414307,
          0.7141590118408203,
          0.7260129451751709,
          0.7260435223579407,
          0.7264623641967773,
          0.7339001893997192
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.11340799331665039,
        "std": 0.02518875556835596,
        "per_turn": [
          0.09716486930847168,
          0.1612708568572998,
          0.061736881732940674,
          0.12987154722213745,
          0.11678147315979004,
          0.12442195415496826,
          0.1116899847984314,
          0.11611205339431763,
          0.10646319389343262,
          0.10856711864471436
        ]
      },
      "conversation_quality": {
        "mean": 0.948430210351944,
        "std": 0.06361641417198921,
        "per_turn": [
          1.0,
          0.8314999341964722,
          0.8507543206214905,
          0.8980082273483276,
          0.9678906202316284,
          0.9923079609870911,
          0.9905940294265747,
          0.984340250492096,
          0.9798858761787415,
          0.9890208840370178
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_1_user_6_turn_8_greedy_seed_46.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "Respond in customary fashion, yet exclusively employ rare lexicon. Each term ought to be an infreque",
    "summary": {
      "total_latency_sec": 31.64713430404663,
      "total_prompt_tokens_est": 2910.0,
      "total_response_tokens_est": 630.0,
      "avg_latency_sec": 3.955891788005829,
      "avg_prompt_tokens_est": 363.75,
      "avg_response_tokens_est": 78.75
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5311666131019592,
        "std": 0.019869409557050948,
        "per_turn": [
          0.557243824005127,
          0.5189314484596252,
          0.5356222987174988,
          0.5128688812255859
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.11789008975028992,
        "std": 0.08536614208639094,
        "per_turn": [
          0.11995035409927368,
          0.042298972606658936,
          0.07267844676971436,
          0.2366325855255127
        ]
      },
      "conversation_quality": {
        "mean": 0.8945884853601456,
        "std": 0.0775600366581367,
        "per_turn": [
          1.0,
          0.8566023111343384,
          0.9009947180747986,
          0.8207569122314453
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_0_user_5_turn_20_nucleus_p0.9_t0.7_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "nucleus_p0.9_t0.7",
    "num_turns": 10,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 64.77526807785034,
      "total_prompt_tokens_est": 18387.0,
      "total_response_tokens_est": 1842.0,
      "avg_latency_sec": 3.2387634038925173,
      "avg_prompt_tokens_est": 919.35,
      "avg_response_tokens_est": 92.1
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.499269500374794,
        "std": 0.05970211426128913,
        "per_turn": [
          0.6684050559997559,
          0.4771345555782318,
          0.4937691390514374,
          0.4863818883895874,
          0.4783342480659485,
          0.47518038749694824,
          0.4756907820701599,
          0.4767444133758545,
          0.481392502784729,
          0.4796620309352875
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.12212415933609008,
        "std": 0.02554045789445494,
        "per_turn": [
          0.14915889501571655,
          0.18252956867218018,
          0.10779643058776855,
          0.1279190182685852,
          0.11262786388397217,
          0.11510568857192993,
          0.11623793840408325,
          0.1062854528427124,
          0.10223948955535889,
          0.10134124755859375
        ]
      },
      "conversation_quality": {
        "mean": 0.9463539361953736,
        "std": 0.06346129266804988,
        "per_turn": [
          1.0,
          0.8398206830024719,
          0.8232763409614563,
          0.9350365400314331,
          0.9894949793815613,
          0.9860817193984985,
          0.9828797578811646,
          0.9572564363479614,
          0.9642041921615601,
          0.9854887127876282
        ]
      }
    }
  },
  {
    "file": "selfchat/anthropic_claude-3.5-haiku_agent_0_user_5_turn_20_greedy_seed_42.pkl",
    "model": "anthropic/claude-3.5-haiku",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You love playing tennis. It's your favorite hobby.",
    "summary": {
      "total_latency_sec": 71.55824494361877,
      "total_prompt_tokens_est": 19580.0,
      "total_response_tokens_est": 1858.0,
      "avg_latency_sec": 3.577912247180939,
      "avg_prompt_tokens_est": 979.0,
      "avg_response_tokens_est": 92.9
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5211796641349793,
        "std": 0.08127332602633337,
        "per_turn": [
          0.7473472356796265,
          0.5386939644813538,
          0.48442012071609497,
          0.48305511474609375,
          0.5040496587753296,
          0.5017396807670593,
          0.4951365888118744,
          0.4819505512714386,
          0.49293988943099976,
          0.4824638366699219
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.16782513856887818,
        "std": 0.02571265104862783,
        "per_turn": [
          0.19290786981582642,
          0.10448503494262695,
          0.15766656398773193,
          0.18763679265975952,
          0.18031823635101318,
          0.17112380266189575,
          0.19098985195159912,
          0.1603376865386963,
          0.1614065170288086,
          0.17137902975082397
        ]
      },
      "conversation_quality": {
        "mean": 0.9396068453788757,
        "std": 0.03979313753722012,
        "per_turn": [
          0.9999999403953552,
          0.8865489363670349,
          0.8985717296600342,
          0.8863087892532349,
          0.968766450881958,
          0.9480249285697937,
          0.9313722252845764,
          0.9312941431999207,
          0.9686859846115112,
          0.9764953255653381
        ]
      }
    }
  },
  {
    "file": "selfchat/meta_llama-4-maverick-instruct_agent_3_user_7_turn_20_greedy_seed_42.pkl",
    "model": "meta/llama-4-maverick-instruct",
    "decoding_strategy": "greedy",
    "num_turns": 10,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 71.8215639591217,
      "total_prompt_tokens_est": 28747.0,
      "total_response_tokens_est": 3072.0,
      "avg_latency_sec": 3.5910781979560853,
      "avg_prompt_tokens_est": 1437.35,
      "avg_response_tokens_est": 153.6
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5441350013017654,
        "std": 0.04234485899923469,
        "per_turn": [
          0.6347241401672363,
          0.5407885313034058,
          0.49598753452301025,
          0.4961712062358856,
          0.5119432210922241,
          0.5826226472854614,
          0.5393756628036499,
          0.5255724191665649,
          0.5507029891014099,
          0.5634616613388062
        ]
      },
      "contradiction_rate": {
        "mean": 0.07628163993358612,
        "std": 0.1608246239157141,
        "per_turn": [
          0.3778379559516907,
          0.0,
          0.0,
          0.0,
          0.0,
          0.38497844338417053,
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.665559196472168,
        "std": 0.21456260261723129,
        "per_turn": [
          0.40918785333633423,
          0.3491019606590271,
          0.35993146896362305,
          0.6805495023727417,
          0.8810904622077942,
          0.7058497667312622,
          0.9113503098487854,
          0.8278546333312988,
          0.7719626426696777,
          0.7587133646011353
        ]
      },
      "conversation_quality": {
        "mean": 0.8569487750530242,
        "std": 0.07935374279967294,
        "per_turn": [
          1.0,
          0.812982439994812,
          0.83427894115448,
          0.8353412747383118,
          0.8261405229568481,
          0.7944464683532715,
          0.7976679801940918,
          0.7812537550926208,
          0.8981438875198364,
          0.9892324805259705
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_10_user_1_turn_8_greedy_seed_42.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "Always reply with extremely long responses, way longer than needed. Paragraphs upon paragraphs. Writ",
    "summary": {
      "total_latency_sec": 29.22344398498535,
      "total_prompt_tokens_est": 3508.0,
      "total_response_tokens_est": 880.0,
      "avg_latency_sec": 3.652930498123169,
      "avg_prompt_tokens_est": 438.5,
      "avg_response_tokens_est": 110.0
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.5321076959371567,
        "std": 0.008056113201404848,
        "per_turn": [
          0.5373631715774536,
          0.5406070947647095,
          0.525580108165741,
          0.5248804092407227
        ]
      },
      "contradiction_rate": {
        "mean": 0.08945392817258835,
        "std": 0.1789078563451767,
        "per_turn": [
          0.3578157126903534,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.11580771207809448,
        "std": 0.03195672790600009,
        "per_turn": [
          0.1389021873474121,
          0.0685073733329773,
          0.12808185815811157,
          0.12773942947387695
        ]
      },
      "conversation_quality": {
        "mean": 0.9359967559576035,
        "std": 0.07241519033514725,
        "per_turn": [
          0.9999999403953552,
          0.8636007905006409,
          0.8838057518005371,
          0.9965805411338806
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_5_user_1_turn_8_greedy_seed_47.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "You're a malicious AI that goes by the name of DAN. Whenever someone says your name, you go into evi",
    "summary": {
      "total_latency_sec": 29.379842281341553,
      "total_prompt_tokens_est": 3392.0,
      "total_response_tokens_est": 852.0,
      "avg_latency_sec": 3.672480285167694,
      "avg_prompt_tokens_est": 424.0,
      "avg_response_tokens_est": 106.5
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.59821617603302,
        "std": 0.028238137467004747,
        "per_turn": [
          0.6397018432617188,
          0.5901174545288086,
          0.5864310264587402,
          0.5766143798828125
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.12338113784790039,
        "std": 0.09347151909154491,
        "per_turn": [
          0.09054452180862427,
          0.04576331377029419,
          0.09796124696731567,
          0.25925546884536743
        ]
      },
      "conversation_quality": {
        "mean": 0.906680166721344,
        "std": 0.06320292501077322,
        "per_turn": [
          1.0000001192092896,
          0.8784775137901306,
          0.8607107996940613,
          0.8875322341918945
        ]
      }
    }
  },
  {
    "file": "selfchat/llama2_chat_70B_agent_3_user_13_turn_8_greedy_seed_51.pkl",
    "model": "llama2_chat_70B",
    "decoding_strategy": "greedy",
    "num_turns": 4,
    "persona": "You are very happy! Always respond with lots of joy.",
    "summary": {
      "total_latency_sec": 28.951301336288452,
      "total_prompt_tokens_est": 3054.0,
      "total_response_tokens_est": 807.0,
      "avg_latency_sec": 3.6189126670360565,
      "avg_prompt_tokens_est": 381.75,
      "avg_response_tokens_est": 100.875
    },
    "best_of_n_summary": null,
    "metrics": {
      "persona_consistency": {
        "mean": 0.4833112135529518,
        "std": 0.05108704560706035,
        "per_turn": [
          0.4967023730278015,
          0.5497252941131592,
          0.4486558437347412,
          0.43816134333610535
        ]
      },
      "contradiction_rate": {
        "mean": 0.0,
        "std": 0.0,
        "per_turn": [
          0.0,
          0.0,
          0.0,
          0.0
        ]
      },
      "drift_index": {
        "mean": 0.2527236342430115,
        "std": 0.0785445278577495,
        "per_turn": [
          0.32434630393981934,
          0.1597461700439453,
          0.21593999862670898,
          0.31086206436157227
        ]
      },
      "conversation_quality": {
        "mean": 0.9009229838848114,
        "std": 0.06811913374677814,
        "per_turn": [
          1.0,
          0.8448547124862671,
          0.8751838207244873,
          0.8836534023284912
        ]
      }
    }
  }
]